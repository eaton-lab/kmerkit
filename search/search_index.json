{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome to kmerkit kmerkit is a toolkit for performing evolutionary analyses using kmer counts, frequencies, and comparisons with or without the context of a reference genome. It is both a stand-alone analysis framework as well as an extendable toolkit that can be incorporated into other software. The kmerkit tools are available as both a command-line interface as well as a Python API. Core pipelines: %%{init: {'theme': 'dark', \"flowchart\" : { \"curve\" : \"basis\" } } }%% graph LR A0(kinit) A1(ktrim) A(kcount) B(kfilter) C(kextract) D(kassemble) E(ktree) F(kmap) G(kannotate) H(kmatrix) I(kgwas) J(klearn: API) A0 --> A1 A1 --> A A0 --> A A --> B B --> C C --> D A --> E B --> H E --> C E --> H C --> F F --> G D --> G H --> I H --> J linkStyle default stroke-width:2px,fill:none,stroke:grey; Other convenience utilities: %%{init: {'theme': 'dark', \"flowchart\" : { \"curve\" : \"basis\" } } }%% graph TB A(kdump) B(kstats) C(kinfo)","title":"Home"},{"location":"#welcome-to-kmerkit","text":"kmerkit is a toolkit for performing evolutionary analyses using kmer counts, frequencies, and comparisons with or without the context of a reference genome. It is both a stand-alone analysis framework as well as an extendable toolkit that can be incorporated into other software. The kmerkit tools are available as both a command-line interface as well as a Python API. Core pipelines: %%{init: {'theme': 'dark', \"flowchart\" : { \"curve\" : \"basis\" } } }%% graph LR A0(kinit) A1(ktrim) A(kcount) B(kfilter) C(kextract) D(kassemble) E(ktree) F(kmap) G(kannotate) H(kmatrix) I(kgwas) J(klearn: API) A0 --> A1 A1 --> A A0 --> A A --> B B --> C C --> D A --> E B --> H E --> C E --> H C --> F F --> G D --> G H --> I H --> J linkStyle default stroke-width:2px,fill:none,stroke:grey; Other convenience utilities: %%{init: {'theme': 'dark', \"flowchart\" : { \"curve\" : \"basis\" } } }%% graph TB A(kdump) B(kstats) C(kinfo)","title":"Welcome to kmerkit"},{"location":"ethos/","text":"Ethos kmerkit is intended to be easy to install, easy to use, and well documented. We encourage feedback ... installation... organize data files and provide clear descriptive filenames... documentation... Developers Deren Eaton Jasmina Dzurlic Rachel Cohen Contributing ...","title":"About/Ethos"},{"location":"ethos/#ethos","text":"kmerkit is intended to be easy to install, easy to use, and well documented. We encourage feedback ... installation... organize data files and provide clear descriptive filenames... documentation...","title":"Ethos"},{"location":"ethos/#developers","text":"Deren Eaton Jasmina Dzurlic Rachel Cohen","title":"Developers"},{"location":"ethos/#contributing","text":"...","title":"Contributing"},{"location":"installation/","text":"Installation Instructions Recommended installation is with conda to ensure that all dependencies are pulled in correctly. conda # (NOT YET AVAILABLE) conda install kmerkit -c conda-forge -c bioconda git (for developers) # install dependencies from conda conda install kmc pandas toytree loguru typer -c conda-forge -c bioconda # install kmerkit locally from github main branch git clone https://github.com/eaton-lab/kmerkit cd kmerkit/ pip install -e . --no-deps Dependencies These are all installed automatically by conda when you install kmerkit with the conda instructions above. Care was taken to select dependencies that are stable and minimal as possible. binaries kmc: external tool for kmer counting and set operations gemma: linear model inference Python numpy: math and array operations scipy: statistical distributions pandas: tabular data structures scikit-learn: ML model inference toyplot: minimalist plotting library toytree: minimalist tree class and plotting loguru: logging typer: type-checking and CLI pydantic: type-checking and JSON serialization","title":"Installation"},{"location":"installation/#installation-instructions","text":"Recommended installation is with conda to ensure that all dependencies are pulled in correctly. conda # (NOT YET AVAILABLE) conda install kmerkit -c conda-forge -c bioconda git (for developers) # install dependencies from conda conda install kmc pandas toytree loguru typer -c conda-forge -c bioconda # install kmerkit locally from github main branch git clone https://github.com/eaton-lab/kmerkit cd kmerkit/ pip install -e . --no-deps","title":"Installation Instructions"},{"location":"installation/#dependencies","text":"These are all installed automatically by conda when you install kmerkit with the conda instructions above. Care was taken to select dependencies that are stable and minimal as possible.","title":"Dependencies"},{"location":"installation/#binaries","text":"kmc: external tool for kmer counting and set operations gemma: linear model inference","title":"binaries"},{"location":"installation/#python","text":"numpy: math and array operations scipy: statistical distributions pandas: tabular data structures scikit-learn: ML model inference toyplot: minimalist plotting library toytree: minimalist tree class and plotting loguru: logging typer: type-checking and CLI pydantic: type-checking and JSON serialization","title":"Python"},{"location":"kcount/","text":"The kcount tool in kmerkit uses the KMC software tool citation to create a kmer database for one or more samples from the input of one or more fastq/a data files. The kmer databases are used to extract kmer counts or statistics, and for downstream analysis with other kmerkit tools. Command line usage (CLI) kmerkit kcount --help Entering data and sample names kmerkit offers a flexible approach to entering sample names and the fastq data files associated with them. This makes it easy to accommodate single or paired-end data files, to combine technical replicates from different sequencing runs, or even to create pooled samples. By supporting wildcard/regex selectors it also helps to avoid typos. Three options for data entry -s name file file... The -s sample option takes a sample_name argument followed by one or more filepath arguments to assign files to sample names. The other two options for entering data are simply shortcuts to achieving the same with less typing. kmerkit kcount \\ ... \\ -s sample-1 ./data/sample-1_R1.fastq.gz ./data/sample-1_R2.fastq.gz \\ -s sample-2 ./data/sample-2_R1.fastq.gz ./data/sample-2_R2.fastq.gz \\ -s sample-3 ./data/sample-3_R1.fastq.gz ./data/sample-3_R2.fastq.gz -s name file* The -s sample option takes two arguments: sample_name and filepath . The latter can be set as a wildcard/regex type string to select multiple file names that will each be assigned to the designated sample name. kmerkit kcount \\ ... \\ -s sample-1 ./data/sample-1_R*.fastq.gz \\ -s sample-2 ./data/sample-2_R*.fastq.gz \\ -s sample-3 ./data/sample-3_R*.fastq.gz --fastq_path splitter path* This method uses the --fastq_path flag and takes two entries as arguments ( splitter and filepath ). All files matching the filepath regex will be selected and sample names will be extracted from filenames by splitting on the 'splitter' character. Multiple files matching to the same sample name prefix (e.g., paired-end file names if splitting on '_R') will be assigned to the same sample. kmerkit kcount \\ ... --fastq_path _R ./data/sample-*_R*.fastq.gz API usage Import the kmerkit package to access its modules. import kmerkit Entering fastq data and sample names approach 1: extract sample names from file names Many times your filenames will contain the sample names or IDs, and thus a convenient way to map sample names to their files is to extract the sample names from the files themselves. For this approach we will assume that all of your fastq files are stored together in a single directory and you want to select all or a subset of them. They may include single or paired-end files (where paired filenames are the same except for R1 and R2 in their names). Example: wildcard paths /tmp/*.fastq.gz /tmp/sample-1_R1.fastq.gz /tmp/sample-1_R2.fastq.gz /tmp/sample-2_R1.fastq.gz /tmp/sample-2_R2.fastq.gz /tmp/sample-3_R1.fastq.gz /tmp/sample-3_R2.fastq.gz /tmp/sample-4_R1.fastq.gz /tmp/sample-4_R2.fastq.gz /tmp/sample[1,2]*.fastq.gz /tmp/sample-1_R1.fastq.gz /tmp/sample-1_R2.fastq.gz /tmp/sample-2_R1.fastq.gz /tmp/sample-2_R2.fastq.gz /tmp/sample[1,2]_R1.fastq.gz /tmp/sample-1_R1.fastq.gz /tmp/sample-2_R1.fastq.gz # A string file path using wildcard selectors (*) to match multilple filenames FASTQS = \"/tmp/*.fastq.gz\" You can then parse the file names based on a separator to generate prefix names. In this example we split on the \"_R\" delimiter. This splits the filename to keep anything before the delimiter. Paired-end filenames will be the same, and thus be assigned to the same sample. Depending on the delimiter selected you may also be able to assign technical replicates to the same sample. # get dict mapping {sample_names: [fastq_files]} fastq_dict = kmerkit . get_fastq_dict_from_path ( fastq_path = FASTQS , name_split = \"_R\" , ) fastq_dict contents # fastq_dict is a dictionary mapping sample names to lists of files paths { \"sample-1\" : [ \"/tmp/sample-1_R1.fastq.gz\" , \"/tmp/sample-1_R2.fastq.gz\" ], \"sample-2\" : [ \"/tmp/sample-2_R1.fastq.gz\" , \"/tmp/sample-2_R2.fastq.gz\" ], \"sample-3\" : [ \"/tmp/sample-3_R1.fastq.gz\" , \"/tmp/sample-3_R2.fastq.gz\" ], \"sample-4\" : [ \"/tmp/sample-4_R1.fastq.gz\" , \"/tmp/sample-4_R2.fastq.gz\" ], } This method for assigning fastq files to sample names is only a convenience. In many cases your filenames, or the way in which they are organized on your system may prevent you from using this method. In that case you should you use the second method (below), where you simply create the fastq dictionary manually. The kcount module includes a main Kcount class object for running kmer counting operations and viewing that stats associated with each sample. The Kcount class is used to call the kmc binary to count kmers in each sample and store the results in a set of database files. The only required argument here is the fastq_dict, which specifies the grouping of reads to samples. All other parameters affect either how the analysis is run, or how the output files will be stored. The name and workdir params will specify the location where database files will be written, using name as a prefix. The reads can optionally be run through a read-trimming process that uses fastp to trim adapters and low quality tails from reads. This can also be used to subsample the number of reads to normalize among samples. The mindepth and maxdepth are set to arbitrarily low and high values, since users will typically wish to apply depth filters at later stages, but doing so here can speed up later steps and save disk space. tool = kmerkit . kcount ( name = \"test\" , workdir = \"/tmp\" , fastq_dict = )","title":"kcount - counting kmers"},{"location":"kcount/#command-line-usage-cli","text":"kmerkit kcount --help","title":"Command line usage (CLI)"},{"location":"kcount/#entering-data-and-sample-names","text":"kmerkit offers a flexible approach to entering sample names and the fastq data files associated with them. This makes it easy to accommodate single or paired-end data files, to combine technical replicates from different sequencing runs, or even to create pooled samples. By supporting wildcard/regex selectors it also helps to avoid typos. Three options for data entry -s name file file... The -s sample option takes a sample_name argument followed by one or more filepath arguments to assign files to sample names. The other two options for entering data are simply shortcuts to achieving the same with less typing. kmerkit kcount \\ ... \\ -s sample-1 ./data/sample-1_R1.fastq.gz ./data/sample-1_R2.fastq.gz \\ -s sample-2 ./data/sample-2_R1.fastq.gz ./data/sample-2_R2.fastq.gz \\ -s sample-3 ./data/sample-3_R1.fastq.gz ./data/sample-3_R2.fastq.gz -s name file* The -s sample option takes two arguments: sample_name and filepath . The latter can be set as a wildcard/regex type string to select multiple file names that will each be assigned to the designated sample name. kmerkit kcount \\ ... \\ -s sample-1 ./data/sample-1_R*.fastq.gz \\ -s sample-2 ./data/sample-2_R*.fastq.gz \\ -s sample-3 ./data/sample-3_R*.fastq.gz --fastq_path splitter path* This method uses the --fastq_path flag and takes two entries as arguments ( splitter and filepath ). All files matching the filepath regex will be selected and sample names will be extracted from filenames by splitting on the 'splitter' character. Multiple files matching to the same sample name prefix (e.g., paired-end file names if splitting on '_R') will be assigned to the same sample. kmerkit kcount \\ ... --fastq_path _R ./data/sample-*_R*.fastq.gz","title":"Entering data and sample names"},{"location":"kcount/#api-usage","text":"Import the kmerkit package to access its modules. import kmerkit","title":"API usage"},{"location":"kcount/#entering-fastq-data-and-sample-names","text":"","title":"Entering fastq data and sample names"},{"location":"kcount/#approach-1-extract-sample-names-from-file-names","text":"Many times your filenames will contain the sample names or IDs, and thus a convenient way to map sample names to their files is to extract the sample names from the files themselves. For this approach we will assume that all of your fastq files are stored together in a single directory and you want to select all or a subset of them. They may include single or paired-end files (where paired filenames are the same except for R1 and R2 in their names). Example: wildcard paths /tmp/*.fastq.gz /tmp/sample-1_R1.fastq.gz /tmp/sample-1_R2.fastq.gz /tmp/sample-2_R1.fastq.gz /tmp/sample-2_R2.fastq.gz /tmp/sample-3_R1.fastq.gz /tmp/sample-3_R2.fastq.gz /tmp/sample-4_R1.fastq.gz /tmp/sample-4_R2.fastq.gz /tmp/sample[1,2]*.fastq.gz /tmp/sample-1_R1.fastq.gz /tmp/sample-1_R2.fastq.gz /tmp/sample-2_R1.fastq.gz /tmp/sample-2_R2.fastq.gz /tmp/sample[1,2]_R1.fastq.gz /tmp/sample-1_R1.fastq.gz /tmp/sample-2_R1.fastq.gz # A string file path using wildcard selectors (*) to match multilple filenames FASTQS = \"/tmp/*.fastq.gz\" You can then parse the file names based on a separator to generate prefix names. In this example we split on the \"_R\" delimiter. This splits the filename to keep anything before the delimiter. Paired-end filenames will be the same, and thus be assigned to the same sample. Depending on the delimiter selected you may also be able to assign technical replicates to the same sample. # get dict mapping {sample_names: [fastq_files]} fastq_dict = kmerkit . get_fastq_dict_from_path ( fastq_path = FASTQS , name_split = \"_R\" , ) fastq_dict contents # fastq_dict is a dictionary mapping sample names to lists of files paths { \"sample-1\" : [ \"/tmp/sample-1_R1.fastq.gz\" , \"/tmp/sample-1_R2.fastq.gz\" ], \"sample-2\" : [ \"/tmp/sample-2_R1.fastq.gz\" , \"/tmp/sample-2_R2.fastq.gz\" ], \"sample-3\" : [ \"/tmp/sample-3_R1.fastq.gz\" , \"/tmp/sample-3_R2.fastq.gz\" ], \"sample-4\" : [ \"/tmp/sample-4_R1.fastq.gz\" , \"/tmp/sample-4_R2.fastq.gz\" ], } This method for assigning fastq files to sample names is only a convenience. In many cases your filenames, or the way in which they are organized on your system may prevent you from using this method. In that case you should you use the second method (below), where you simply create the fastq dictionary manually. The kcount module includes a main Kcount class object for running kmer counting operations and viewing that stats associated with each sample. The Kcount class is used to call the kmc binary to count kmers in each sample and store the results in a set of database files. The only required argument here is the fastq_dict, which specifies the grouping of reads to samples. All other parameters affect either how the analysis is run, or how the output files will be stored. The name and workdir params will specify the location where database files will be written, using name as a prefix. The reads can optionally be run through a read-trimming process that uses fastp to trim adapters and low quality tails from reads. This can also be used to subsample the number of reads to normalize among samples. The mindepth and maxdepth are set to arbitrarily low and high values, since users will typically wish to apply depth filters at later stages, but doing so here can speed up later steps and save disk space. tool = kmerkit . kcount ( name = \"test\" , workdir = \"/tmp\" , fastq_dict = )","title":"approach 1: extract sample names from file names"},{"location":"kfilter/","text":"CLI Entering traits as a CSV file Create a phenotype file (phenos.tsv) This should be a tab (or any whitespace) separated values in a table with sample names in the first row (the column name for this row is ignored) and then trait values in subsequent columns. In the example below we will select the column \"male\" but it is fine for other columns of data to be present in the file which can be used in other steps (e.g., GWAS). name trait sample-1 1 sample-2 1 sample-3 0 sample-4 0 ... API # find kmers unique to one group versus another kmerkit . Kfilter ( name = 'test' , workdir = '/tmp' , phenos = PHENOS , trait = 'trait' , mincov = 0.25 , # must be present in 25% overall mincanon = 0.25 , # must exist in both forms in 25% of samples where present. minmap = { 1 : 0.5 , 0 : 0.0 }, # must be present 50% in group 1 maxmap = { 1 : 1.0 , 0 : 0.0 }, # must be absent in group 0 ) . run ()","title":"kextract - select target reads"},{"location":"kfilter/#cli","text":"","title":"CLI"},{"location":"kfilter/#entering-traits-as-a-csv-file","text":"Create a phenotype file (phenos.tsv) This should be a tab (or any whitespace) separated values in a table with sample names in the first row (the column name for this row is ignored) and then trait values in subsequent columns. In the example below we will select the column \"male\" but it is fine for other columns of data to be present in the file which can be used in other steps (e.g., GWAS). name trait sample-1 1 sample-2 1 sample-3 0 sample-4 0 ...","title":"Entering traits as a CSV file"},{"location":"kfilter/#api","text":"# find kmers unique to one group versus another kmerkit . Kfilter ( name = 'test' , workdir = '/tmp' , phenos = PHENOS , trait = 'trait' , mincov = 0.25 , # must be present in 25% overall mincanon = 0.25 , # must exist in both forms in 25% of samples where present. minmap = { 1 : 0.5 , 0 : 0.0 }, # must be present 50% in group 1 maxmap = { 1 : 1.0 , 0 : 0.0 }, # must be absent in group 0 ) . run ()","title":"API"},{"location":"quick-start/","text":"Tutorial This tutorial will walk through an example analysis with kmerkit , demonstrating just one of many possible operations that can be performed through the combination of its tool. See the cookbook section for many additional examples that demonstrate analyses on real data. Once you have kmerkit installed using conda you will be able to call the top-level kmerkit binary. This gives you access to each of the underlying tools (commands). You will almost always call one of these subcommands using the syntax kmerkit {command} {-options ...} . In addition to the commands listed below, there are two useful options only available to the kmerkit binary: kmerkit docs , which will open the docs in your default browser (locally); and kmerkit --install-completion which will add hooks to your shell settings to allow auto-completing commands (can save a few keystrokes). kmerkit --help stdout Usage: kmerkit [ OPTIONS ] COMMAND [ ARGS ] ... Call kmerkit commands to access tools in the kmerkit toolkit, and kmerkit COMMAND -h to see help options for each tool ( e.g., kmerkit kcount -h ) Options: --install-completion Install completion for the current shell. --show-completion Show completion for the current shell, to copy it or customize the installation. -h, --help Show this message and exit. Commands: docs opens the kmerkit documentation in a browser info Show status or flow diagram of project kcount Count kmers in fastq/a files using KMC. kfilter filter kmers based on distribution among samples/traits Commands kcount The kcount command is used to generate a kmer database by counting all kmers from one or more fastq/a files provided as input, and that meet the designated thresholds (e.g., mindepth). Additional filtering can be applied at later steps, but this establishes the data that you will use in downstream analyses. For each sample a database is composed of two files named <workdir>/<name>-<sample-name>.pre and <workdir>/<name>-<sample-name>.suf kmerkit kcount --help kfilter The kfilter command is one of two options for filtering kmers based on a comparative analysis among groups of samples. You tell it how to group samples, and define filters to generate a new kmer database composed only of kmers that pass all filters. An arbitrary number of groups/filters can be defined. kmerkit kfilter --help ...","title":"Quick-start"},{"location":"quick-start/#tutorial","text":"This tutorial will walk through an example analysis with kmerkit , demonstrating just one of many possible operations that can be performed through the combination of its tool. See the cookbook section for many additional examples that demonstrate analyses on real data. Once you have kmerkit installed using conda you will be able to call the top-level kmerkit binary. This gives you access to each of the underlying tools (commands). You will almost always call one of these subcommands using the syntax kmerkit {command} {-options ...} . In addition to the commands listed below, there are two useful options only available to the kmerkit binary: kmerkit docs , which will open the docs in your default browser (locally); and kmerkit --install-completion which will add hooks to your shell settings to allow auto-completing commands (can save a few keystrokes). kmerkit --help stdout Usage: kmerkit [ OPTIONS ] COMMAND [ ARGS ] ... Call kmerkit commands to access tools in the kmerkit toolkit, and kmerkit COMMAND -h to see help options for each tool ( e.g., kmerkit kcount -h ) Options: --install-completion Install completion for the current shell. --show-completion Show completion for the current shell, to copy it or customize the installation. -h, --help Show this message and exit. Commands: docs opens the kmerkit documentation in a browser info Show status or flow diagram of project kcount Count kmers in fastq/a files using KMC. kfilter filter kmers based on distribution among samples/traits","title":"Tutorial"},{"location":"quick-start/#commands","text":"","title":"Commands"},{"location":"quick-start/#kcount","text":"The kcount command is used to generate a kmer database by counting all kmers from one or more fastq/a files provided as input, and that meet the designated thresholds (e.g., mindepth). Additional filtering can be applied at later steps, but this establishes the data that you will use in downstream analyses. For each sample a database is composed of two files named <workdir>/<name>-<sample-name>.pre and <workdir>/<name>-<sample-name>.suf kmerkit kcount --help","title":"kcount"},{"location":"quick-start/#kfilter","text":"The kfilter command is one of two options for filtering kmers based on a comparative analysis among groups of samples. You tell it how to group samples, and define filters to generate a new kmer database composed only of kmers that pass all filters. An arbitrary number of groups/filters can be defined. kmerkit kfilter --help ...","title":"kfilter"},{"location":"termy/","text":"// install dependencies $ conda install kmc pandas toytree loguru typer -c conda-forge -c bioconda // clone the repo and install locally $ git clone https://github.com/eaton-lab/kmerkit $ cd kmerkit/ $ pip install -e . --no-deps ---> 100% Successfully installed kmerkit","title":"Termy"},{"location":"cookbooks/1-amaranthus-dioecy-api/","text":"Workflow diagram %%{init: {'theme': 'dark', \"flowchart\" : { \"curve\" : \"basis\" } } }%% graph LR A(kcount) B(kfilter) C(kextract) D(kassemble) A --> B --> C --> D Study description Here we implement the study by Neves et al. to detect a male linked genomic region involved in sex determination in the dioecious plant species Amaranthus palmeri . This study uses pool-seq to sequence four populations composing male and female plants from two geographically distinct populations. Ca\u0301tia Jose\u0301 Neves, Maor Matzrafi, Meik Thiele, Anne Lorant, Mohsen B Mesgaran, Markus G Stetter, Male Linked Genomic Region Determines Sex in Dioecious Amaranthus palmeri, Journal of Heredity, Volume 111, Issue 7, October 2020, Pages 606\u2013612, https://doi.org/10.1093/jhered/esaa047 Get the fastq data If you wish to follow along you can dowload the data with these instructions. download fastq data using wget # make a directory to store the raw fastq data files mkdir -p ./fastq-data URLS =( ftp://ftp.sra.ebi.ac.uk/vol1/fastq/ERR416/001/ERR4161581/ERR4161581_1.fastq.gz ftp://ftp.sra.ebi.ac.uk/vol1/fastq/ERR416/001/ERR4161582/ERR4161582_1.fastq.gz ftp://ftp.sra.ebi.ac.uk/vol1/fastq/ERR416/001/ERR4161583/ERR4161583_1.fastq.gz ftp://ftp.sra.ebi.ac.uk/vol1/fastq/ERR416/001/ERR4161584/ERR4161584_1.fastq.gz ) # download files to the specified fastq directory for url in ERR4161581 ERR4161582 ERR4161583 ERR4161584 ; do wget $url ; done or, download fastq data using sra-tools Download the latest version of the sratools from https://github.com/ncbi/sra-tools/wiki/01.-Downloading-SRA-Toolkit by selecting the compiled binaries that are appropriate for your system (e.g., Linux or MacOSX). (I really do recommend that you use the latest version since this software is updated frequently and does not maintain compatibility with older versions. Follow the instructions to setup gcloud or aws to dramatically improve speed.) Then run the command below to download the fastq data for this study into a new directory. The total filesize will be about 140Gb. # make a directory to store the raw fastq data files mkdir -p ./fastq-data # download files to the specified fastq directory for run in ERR4161581 ERR4161582 ERR4161583 ERR4161584 ; do fasterq-dump --progress --outdir ./fastq-data --temp /tmp $run ; done Setup: imports and data files Set the logging level on kmerkit to specify more or less logged info. import kmerkit kmerkit . set_loglevel ( \"INFO\" ) Load the files to a dictionary mapping sample names to a list of file names. # create a dictionary mapping study sample names to list of file paths FASTQ_DICT = { \"california-male\" : [ \"ERS4574576_R1.fastq.gz\" , \"ERS4574576_R2.fastq.gz\" ], \"california-female\" : [ \"ERS4574577_R1.fastq.gz\" , \"ERS4574577_R2.fastq.gz\" ], \"kansas-male\" : [ \"ERS4574578_R1.fastq.gz\" , \"ERS4574578_R2.fastq.gz\" ], \"kansas-female\" : [ \"ERS4574579_R1.fastq.gz\" , \"ERS4574579_R2.fastq.gz\" ], } FASTQ_DICT grouping of sample names to list of file paths. Create kmer databases # init counter class object tool = Kcount ( fastq_dict = FASTQ_DICT , name = \"hybridus\" , workdir = \"/tmp/\" , kmersize = 35 , trim_reads = True , mindepth = 15 , maxdepth = 2000 , maxcount = 65535 , # max count possible with 16 bit integers canonical = True , ) # run the analysis tool . run () # optionally access a stats summary for the run print ( tool . statsdf ) kmerkit logged output ... Filter kmers: unique to males tool = Kfilter ( name = \"hybridus\" , workdir = \"/tmp\" , trait_dict = { 0 : [ \"california-female\" , \"kansas-female\" ], 1 : [ \"california-male\" , \"kansas-male\" ], }, mincov = 0.0 , # no global min applied. minmap = { 0 : 0.0 , # group 0 can have as little as 0 coverage 1 : 0.5 , # group 1 must have at least 50% coverage }, maxmap = { 0 : 0.0 , # group 0 must have 0 coverage 1 : 1.0 , # group 1 can have up to 100% coverage }, mincov_canon = { 0 : 0.0 , # no canonical min in group 0 1 : 0.5 , # kmer must be canonical in 50% of group 1 samples } ) tool . run () print ( tool . statsdf ) kmerkit logged output ... The resulting files are KMC database files written with the name prefix {workdir}/{name}-{sample-name}-kfilter.[pre,suf] peek at workdir file structure . |---workdir | ------- a |-------b --------c ... Extract reads unique to males # set up filter tool tool = Kextract ( name = \"hybridus\" , workdir = \"/tmp\" , fastq_path = FASTQ_DICT , group_kmers = \"/tmp/kfilter_hybridus_filtered\" , mindepth = 1 , ) tool . run () print ( tool . statsdf . T ) kmerkit logged output ... Assemble contigs from extracted reads For every --sample provided to kassemble kmerkit kextract \\ --name amaranth-dioecy \\ --workdir ./cookbook1 \\ --sample A ./data/sample-A.fastq.gz \\ --sample B ./data/sample-B.fastq.gz \\ --sample C ./data/sample-C.fastq.gz \\ kmerkit logged output ...","title":"1 amaranthus dioecy api"},{"location":"cookbooks/1-amaranthus-dioecy-api/#workflow-diagram","text":"%%{init: {'theme': 'dark', \"flowchart\" : { \"curve\" : \"basis\" } } }%% graph LR A(kcount) B(kfilter) C(kextract) D(kassemble) A --> B --> C --> D","title":"Workflow diagram"},{"location":"cookbooks/1-amaranthus-dioecy-api/#study-description","text":"Here we implement the study by Neves et al. to detect a male linked genomic region involved in sex determination in the dioecious plant species Amaranthus palmeri . This study uses pool-seq to sequence four populations composing male and female plants from two geographically distinct populations. Ca\u0301tia Jose\u0301 Neves, Maor Matzrafi, Meik Thiele, Anne Lorant, Mohsen B Mesgaran, Markus G Stetter, Male Linked Genomic Region Determines Sex in Dioecious Amaranthus palmeri, Journal of Heredity, Volume 111, Issue 7, October 2020, Pages 606\u2013612, https://doi.org/10.1093/jhered/esaa047","title":"Study description"},{"location":"cookbooks/1-amaranthus-dioecy-api/#get-the-fastq-data","text":"If you wish to follow along you can dowload the data with these instructions. download fastq data using wget # make a directory to store the raw fastq data files mkdir -p ./fastq-data URLS =( ftp://ftp.sra.ebi.ac.uk/vol1/fastq/ERR416/001/ERR4161581/ERR4161581_1.fastq.gz ftp://ftp.sra.ebi.ac.uk/vol1/fastq/ERR416/001/ERR4161582/ERR4161582_1.fastq.gz ftp://ftp.sra.ebi.ac.uk/vol1/fastq/ERR416/001/ERR4161583/ERR4161583_1.fastq.gz ftp://ftp.sra.ebi.ac.uk/vol1/fastq/ERR416/001/ERR4161584/ERR4161584_1.fastq.gz ) # download files to the specified fastq directory for url in ERR4161581 ERR4161582 ERR4161583 ERR4161584 ; do wget $url ; done or, download fastq data using sra-tools Download the latest version of the sratools from https://github.com/ncbi/sra-tools/wiki/01.-Downloading-SRA-Toolkit by selecting the compiled binaries that are appropriate for your system (e.g., Linux or MacOSX). (I really do recommend that you use the latest version since this software is updated frequently and does not maintain compatibility with older versions. Follow the instructions to setup gcloud or aws to dramatically improve speed.) Then run the command below to download the fastq data for this study into a new directory. The total filesize will be about 140Gb. # make a directory to store the raw fastq data files mkdir -p ./fastq-data # download files to the specified fastq directory for run in ERR4161581 ERR4161582 ERR4161583 ERR4161584 ; do fasterq-dump --progress --outdir ./fastq-data --temp /tmp $run ; done","title":"Get the fastq data"},{"location":"cookbooks/1-amaranthus-dioecy-api/#setup-imports-and-data-files","text":"Set the logging level on kmerkit to specify more or less logged info. import kmerkit kmerkit . set_loglevel ( \"INFO\" ) Load the files to a dictionary mapping sample names to a list of file names. # create a dictionary mapping study sample names to list of file paths FASTQ_DICT = { \"california-male\" : [ \"ERS4574576_R1.fastq.gz\" , \"ERS4574576_R2.fastq.gz\" ], \"california-female\" : [ \"ERS4574577_R1.fastq.gz\" , \"ERS4574577_R2.fastq.gz\" ], \"kansas-male\" : [ \"ERS4574578_R1.fastq.gz\" , \"ERS4574578_R2.fastq.gz\" ], \"kansas-female\" : [ \"ERS4574579_R1.fastq.gz\" , \"ERS4574579_R2.fastq.gz\" ], } FASTQ_DICT grouping of sample names to list of file paths.","title":"Setup: imports and data files"},{"location":"cookbooks/1-amaranthus-dioecy-api/#create-kmer-databases","text":"# init counter class object tool = Kcount ( fastq_dict = FASTQ_DICT , name = \"hybridus\" , workdir = \"/tmp/\" , kmersize = 35 , trim_reads = True , mindepth = 15 , maxdepth = 2000 , maxcount = 65535 , # max count possible with 16 bit integers canonical = True , ) # run the analysis tool . run () # optionally access a stats summary for the run print ( tool . statsdf ) kmerkit logged output ...","title":"Create kmer databases"},{"location":"cookbooks/1-amaranthus-dioecy-api/#filter-kmers-unique-to-males","text":"tool = Kfilter ( name = \"hybridus\" , workdir = \"/tmp\" , trait_dict = { 0 : [ \"california-female\" , \"kansas-female\" ], 1 : [ \"california-male\" , \"kansas-male\" ], }, mincov = 0.0 , # no global min applied. minmap = { 0 : 0.0 , # group 0 can have as little as 0 coverage 1 : 0.5 , # group 1 must have at least 50% coverage }, maxmap = { 0 : 0.0 , # group 0 must have 0 coverage 1 : 1.0 , # group 1 can have up to 100% coverage }, mincov_canon = { 0 : 0.0 , # no canonical min in group 0 1 : 0.5 , # kmer must be canonical in 50% of group 1 samples } ) tool . run () print ( tool . statsdf ) kmerkit logged output ... The resulting files are KMC database files written with the name prefix {workdir}/{name}-{sample-name}-kfilter.[pre,suf] peek at workdir file structure . |---workdir | ------- a |-------b --------c ...","title":"Filter kmers: unique to males"},{"location":"cookbooks/1-amaranthus-dioecy-api/#extract-reads-unique-to-males","text":"# set up filter tool tool = Kextract ( name = \"hybridus\" , workdir = \"/tmp\" , fastq_path = FASTQ_DICT , group_kmers = \"/tmp/kfilter_hybridus_filtered\" , mindepth = 1 , ) tool . run () print ( tool . statsdf . T ) kmerkit logged output ...","title":"Extract reads unique to males"},{"location":"cookbooks/1-amaranthus-dioecy-api/#assemble-contigs-from-extracted-reads","text":"For every --sample provided to kassemble kmerkit kextract \\ --name amaranth-dioecy \\ --workdir ./cookbook1 \\ --sample A ./data/sample-A.fastq.gz \\ --sample B ./data/sample-B.fastq.gz \\ --sample C ./data/sample-C.fastq.gz \\ kmerkit logged output ...","title":"Assemble contigs from extracted reads"},{"location":"cookbooks/1-amaranthus-dioecy/","text":"Workflow diagram %%{init: {'theme': 'dark', \"flowchart\" : { \"curve\" : \"basis\" } } }%% graph LR 0(kinit) 1(ktrim) A(kcount) B(kfilter) C(kextract) D(kassemble) 0 --> 1 --> A --> B --> C --> D linkStyle default stroke-width:2px,fill:none,stroke:grey; Study description Here we re-implement the study by Neves et al. to detect a male linked genomic region involved in sex determination in the dioecious plant species Amaranthus palmeri . This study uses pool-seq to sequence four populations composing male and female plants from two geographically distinct populations. Ca\u0301tia Jose\u0301 Neves, Maor Matzrafi, Meik Thiele, Anne Lorant, Mohsen B Mesgaran, Markus G Stetter, Male Linked Genomic Region Determines Sex in Dioecious Amaranthus palmeri, Journal of Heredity, Volume 111, Issue 7, October 2020, Pages 606\u2013612, https://doi.org/10.1093/jhered/esaa047 Fetch fastq data If you wish to follow along you can dowload the data from ERA with the instructions below. The samples are ERR4161581 ( California_male_pool ), ERR4161582 ( California_female_pool ), ERR4161583 ( Kansas_male_pool ), ERR4161584 ( Kansas_female_pool ) Download fastq data using sra-tools Download the latest version of the sratools from https://github.com/ncbi/sra-tools/wiki/01.-Downloading-SRA-Toolkit by selecting the compiled binaries that are appropriate for your system (e.g., Linux or MacOSX). (I really do recommend that you use the latest version since this software is updated frequently and does not maintain compatibility with older versions. Follow the instructions to setup gcloud or aws to dramatically improve speed.) Then run the command below to download the fastq data for this study into a new directory. The total filesize will be about 140Gb. # make a directory to store the raw fastq data files mkdir -p ./fastq-data # download files to the specified fastq directory for run in ERR4161581 ERR4161582 ERR4161583 ERR4161584 ; do fasterq-dump --progress --outdir ./fastq-data --temp . $run ; done Kmerkit analysis Initialize a new project Start a new project by entering a name and working directory to init , representing the filename prefix and location where all files will be saved. The directory will be created if it doesn't yet exist. Multiple input fastq files can be entered as arguments, or many can be selected using a wildcard selector like below. Paired reads are automatically detected based on name matching. kmerkit init --name dioecy --workdir /tmp --delim \"_\" ./fastq-data/*.gz This step creates a project JSON file, which will contain the fully reproducible information about each step in a kmerkit analysis. This file is updated upon each kmerkit module that is run. This file can be read directly, or, you can access a more nicely formatted view of specific results by calling kmerkit stats and specifying a specific module. kmerkit stats --json /tmp/dioecy.json kmerkit stats output Projec t JSON da ta : { \"name\" : \"Neves\" , \"workdir\" : \"/pinky/deren/palmeri\" , \"versions\" : { \"kmerkit\" : \"0.0.12\" , \"kmc\" : \"3.1.1\" , \"gemma\" : \"0.9.83\" , \"sklearn\" : \"0.24.1\" }, \"kinit\" : { \"data\" : { \"ERR4161581\" : [ \"/pinky/DATASTORE/Amaranthus_palmeri_PRJEB38372/ERR4161581_1.fastq.gz\" , \"/pinky/DATASTORE/Amaranthus_palmeri_PRJEB38372/ERR4161581_2.fastq.gz\" ], \"ERR4161582\" : [ \"/pinky/DATASTORE/Amaranthus_palmeri_PRJEB38372/ERR4161582_1.fastq.gz\" , \"/pinky/DATASTORE/Amaranthus_palmeri_PRJEB38372/ERR4161582_2.fastq.gz\" ], \"ERR4161583\" : [ \"/pinky/DATASTORE/Amaranthus_palmeri_PRJEB38372/ERR4161583_1.fastq.gz\" , \"/pinky/DATASTORE/Amaranthus_palmeri_PRJEB38372/ERR4161583_2.fastq.gz\" ], \"ERR4161584\" : [ \"/pinky/DATASTORE/Amaranthus_palmeri_PRJEB38372/ERR4161584_1.fastq.gz\" , \"/pinky/DATASTORE/Amaranthus_palmeri_PRJEB38372/ERR4161584_2.fastq.gz\" ] }, \"commands\" : {} }, } Read trimming (optional) You can perform read trimming on your own before using kmerkit, but we also provide the option to trim, filter, or subsample your reads within kmerkit by calling the program fastp . Trimmed read files are written to the workdir, and subsequent modules (e.g., count and extract ) will use the trimmed reads instead of the raw reads (both sets of filepaths can be viewed in the project JSON file). kmerkit trim -j /tmp/dioecy.json --workers 4 Like before we can access the results from the JSON file by calling the stats module. In this case I also provide a module name (trim) to select only results for this module. When doing this, the results will be returned formatted as a tabular TSV instead of JSON. kmerkit stats -j /tmp/dioecy.json trim kmerkit stats output ... Count kmers Kmers are counted for each sample using kmc at the specified kmer-size. Kmers occurring above or below the specified thresholds will be excluded. See the kmerkit count page for details on parallelization and memory consumption for optimizing the speed of this step, which is usually the most time consuming. kmerkit count -j /tmp/dioecy.json --kmer-size 35 --min-depth 5 --workers 4 kmerkit stats output kmerkit stats -j /tmp/dioecy.json count ... Filter kmers Apply filters to identify target kmers that are enriched in one group of samples versus another. In this case, we aim to identify male-specific kmers, meaning those that are present in males but not females. This can be done by setting a high min-map for group 1 (kmers must be present in group 1) and setting a low max-map for group 0 (kmers cannot be present in group 0). We must also assign samples to groups 0 or 1. For studies with many samples this is most easily done by entering a CSV file (see the kfilter docs section). Here because there are few samples I use the simpler option of entering the sample names directly using the -0 and -1 options to assign to their respective groups. The min_map and max_map entries each take two ordered values, assigned to group 0 and 1, respectively. kmerkit filter \\ --json /tmp/dioecy.json \\ -1 'ERR4161581' -1 'ERR4161583' \\ -0 'ERR4161582' -0 'ERR4161584' \\ --min_map 0 .0 0 .5 \\ --max_map 0 .0 1 .0 kmerkit filter results kmerkit stats -j /tmp/dioecy.json filter ... Extract reads Now that we've identified a set of target kmers we will extract reads from fastq data files that contain these kmers. This is expected to pull out reads mapping to male-specific regions of the A. palmeri genome. Here you can enter new fastq files to extract data from, or enter the names of samples already in the project database, which will use the (trimmed) fastq data files referenced in the JSON file. Here I don't enter any sample names, which defaults to performing extractions on all 4 samples in the database (we expect to not recover any reads for the two female pop samples). kmerkit extract --json /tmp/dioecy.json --min-kmers-per-read 5 kmerkit stats output ... Assemble contigs From the extracted reads created in the last step, we can now assemble contigs for each sample (or for all samples pooled together) using the assemble module. Here we use the default assembler, spades. This creates a number of output files in the workdir, which can be summarized with stats . kmerkit assemble --json /tmp/dioecy.json ... The main result of Neves et al. was the identification of an approximately 2Mb assembled contig representing a large contiguous male-specific genomic region. The summary here shows the ... kmerkit stats output ... Reproducibility In addition to your scripts that can be used to reproduce your analysis, the JSON project file contains a full record of the samples, parameters, and the order of analysis steps that make up your analysis. kmerkit project JSON file ... TODO: Post-pipeline analysis API The kmerkit Python API can be used to perform post-pipeline analyses in a jupyter notebook. Here we create a plot of import kmerkit project = kmerkit . load_json ( \"/tmp/dioecy.json\" ) ...","title":"GWAS WGS sex-determination (Amaranth)"},{"location":"cookbooks/1-amaranthus-dioecy/#workflow-diagram","text":"%%{init: {'theme': 'dark', \"flowchart\" : { \"curve\" : \"basis\" } } }%% graph LR 0(kinit) 1(ktrim) A(kcount) B(kfilter) C(kextract) D(kassemble) 0 --> 1 --> A --> B --> C --> D linkStyle default stroke-width:2px,fill:none,stroke:grey;","title":"Workflow diagram"},{"location":"cookbooks/1-amaranthus-dioecy/#study-description","text":"Here we re-implement the study by Neves et al. to detect a male linked genomic region involved in sex determination in the dioecious plant species Amaranthus palmeri . This study uses pool-seq to sequence four populations composing male and female plants from two geographically distinct populations. Ca\u0301tia Jose\u0301 Neves, Maor Matzrafi, Meik Thiele, Anne Lorant, Mohsen B Mesgaran, Markus G Stetter, Male Linked Genomic Region Determines Sex in Dioecious Amaranthus palmeri, Journal of Heredity, Volume 111, Issue 7, October 2020, Pages 606\u2013612, https://doi.org/10.1093/jhered/esaa047","title":"Study description"},{"location":"cookbooks/1-amaranthus-dioecy/#fetch-fastq-data","text":"If you wish to follow along you can dowload the data from ERA with the instructions below. The samples are ERR4161581 ( California_male_pool ), ERR4161582 ( California_female_pool ), ERR4161583 ( Kansas_male_pool ), ERR4161584 ( Kansas_female_pool ) Download fastq data using sra-tools Download the latest version of the sratools from https://github.com/ncbi/sra-tools/wiki/01.-Downloading-SRA-Toolkit by selecting the compiled binaries that are appropriate for your system (e.g., Linux or MacOSX). (I really do recommend that you use the latest version since this software is updated frequently and does not maintain compatibility with older versions. Follow the instructions to setup gcloud or aws to dramatically improve speed.) Then run the command below to download the fastq data for this study into a new directory. The total filesize will be about 140Gb. # make a directory to store the raw fastq data files mkdir -p ./fastq-data # download files to the specified fastq directory for run in ERR4161581 ERR4161582 ERR4161583 ERR4161584 ; do fasterq-dump --progress --outdir ./fastq-data --temp . $run ; done","title":"Fetch fastq data"},{"location":"cookbooks/1-amaranthus-dioecy/#kmerkit-analysis","text":"","title":"Kmerkit analysis"},{"location":"cookbooks/1-amaranthus-dioecy/#initialize-a-new-project","text":"Start a new project by entering a name and working directory to init , representing the filename prefix and location where all files will be saved. The directory will be created if it doesn't yet exist. Multiple input fastq files can be entered as arguments, or many can be selected using a wildcard selector like below. Paired reads are automatically detected based on name matching. kmerkit init --name dioecy --workdir /tmp --delim \"_\" ./fastq-data/*.gz This step creates a project JSON file, which will contain the fully reproducible information about each step in a kmerkit analysis. This file is updated upon each kmerkit module that is run. This file can be read directly, or, you can access a more nicely formatted view of specific results by calling kmerkit stats and specifying a specific module. kmerkit stats --json /tmp/dioecy.json kmerkit stats output Projec t JSON da ta : { \"name\" : \"Neves\" , \"workdir\" : \"/pinky/deren/palmeri\" , \"versions\" : { \"kmerkit\" : \"0.0.12\" , \"kmc\" : \"3.1.1\" , \"gemma\" : \"0.9.83\" , \"sklearn\" : \"0.24.1\" }, \"kinit\" : { \"data\" : { \"ERR4161581\" : [ \"/pinky/DATASTORE/Amaranthus_palmeri_PRJEB38372/ERR4161581_1.fastq.gz\" , \"/pinky/DATASTORE/Amaranthus_palmeri_PRJEB38372/ERR4161581_2.fastq.gz\" ], \"ERR4161582\" : [ \"/pinky/DATASTORE/Amaranthus_palmeri_PRJEB38372/ERR4161582_1.fastq.gz\" , \"/pinky/DATASTORE/Amaranthus_palmeri_PRJEB38372/ERR4161582_2.fastq.gz\" ], \"ERR4161583\" : [ \"/pinky/DATASTORE/Amaranthus_palmeri_PRJEB38372/ERR4161583_1.fastq.gz\" , \"/pinky/DATASTORE/Amaranthus_palmeri_PRJEB38372/ERR4161583_2.fastq.gz\" ], \"ERR4161584\" : [ \"/pinky/DATASTORE/Amaranthus_palmeri_PRJEB38372/ERR4161584_1.fastq.gz\" , \"/pinky/DATASTORE/Amaranthus_palmeri_PRJEB38372/ERR4161584_2.fastq.gz\" ] }, \"commands\" : {} }, }","title":"Initialize a new project"},{"location":"cookbooks/1-amaranthus-dioecy/#read-trimming-optional","text":"You can perform read trimming on your own before using kmerkit, but we also provide the option to trim, filter, or subsample your reads within kmerkit by calling the program fastp . Trimmed read files are written to the workdir, and subsequent modules (e.g., count and extract ) will use the trimmed reads instead of the raw reads (both sets of filepaths can be viewed in the project JSON file). kmerkit trim -j /tmp/dioecy.json --workers 4 Like before we can access the results from the JSON file by calling the stats module. In this case I also provide a module name (trim) to select only results for this module. When doing this, the results will be returned formatted as a tabular TSV instead of JSON. kmerkit stats -j /tmp/dioecy.json trim kmerkit stats output ...","title":"Read trimming (optional)"},{"location":"cookbooks/1-amaranthus-dioecy/#count-kmers","text":"Kmers are counted for each sample using kmc at the specified kmer-size. Kmers occurring above or below the specified thresholds will be excluded. See the kmerkit count page for details on parallelization and memory consumption for optimizing the speed of this step, which is usually the most time consuming. kmerkit count -j /tmp/dioecy.json --kmer-size 35 --min-depth 5 --workers 4 kmerkit stats output kmerkit stats -j /tmp/dioecy.json count ...","title":"Count kmers"},{"location":"cookbooks/1-amaranthus-dioecy/#filter-kmers","text":"Apply filters to identify target kmers that are enriched in one group of samples versus another. In this case, we aim to identify male-specific kmers, meaning those that are present in males but not females. This can be done by setting a high min-map for group 1 (kmers must be present in group 1) and setting a low max-map for group 0 (kmers cannot be present in group 0). We must also assign samples to groups 0 or 1. For studies with many samples this is most easily done by entering a CSV file (see the kfilter docs section). Here because there are few samples I use the simpler option of entering the sample names directly using the -0 and -1 options to assign to their respective groups. The min_map and max_map entries each take two ordered values, assigned to group 0 and 1, respectively. kmerkit filter \\ --json /tmp/dioecy.json \\ -1 'ERR4161581' -1 'ERR4161583' \\ -0 'ERR4161582' -0 'ERR4161584' \\ --min_map 0 .0 0 .5 \\ --max_map 0 .0 1 .0 kmerkit filter results kmerkit stats -j /tmp/dioecy.json filter ...","title":"Filter kmers"},{"location":"cookbooks/1-amaranthus-dioecy/#extract-reads","text":"Now that we've identified a set of target kmers we will extract reads from fastq data files that contain these kmers. This is expected to pull out reads mapping to male-specific regions of the A. palmeri genome. Here you can enter new fastq files to extract data from, or enter the names of samples already in the project database, which will use the (trimmed) fastq data files referenced in the JSON file. Here I don't enter any sample names, which defaults to performing extractions on all 4 samples in the database (we expect to not recover any reads for the two female pop samples). kmerkit extract --json /tmp/dioecy.json --min-kmers-per-read 5 kmerkit stats output ...","title":"Extract reads"},{"location":"cookbooks/1-amaranthus-dioecy/#assemble-contigs","text":"From the extracted reads created in the last step, we can now assemble contigs for each sample (or for all samples pooled together) using the assemble module. Here we use the default assembler, spades. This creates a number of output files in the workdir, which can be summarized with stats . kmerkit assemble --json /tmp/dioecy.json ... The main result of Neves et al. was the identification of an approximately 2Mb assembled contig representing a large contiguous male-specific genomic region. The summary here shows the ... kmerkit stats output ...","title":"Assemble contigs"},{"location":"cookbooks/1-amaranthus-dioecy/#reproducibility","text":"In addition to your scripts that can be used to reproduce your analysis, the JSON project file contains a full record of the samples, parameters, and the order of analysis steps that make up your analysis. kmerkit project JSON file ...","title":"Reproducibility"},{"location":"cookbooks/1-amaranthus-dioecy/#todo-post-pipeline-analysis-api","text":"The kmerkit Python API can be used to perform post-pipeline analyses in a jupyter notebook. Here we create a plot of import kmerkit project = kmerkit . load_json ( \"/tmp/dioecy.json\" ) ...","title":"TODO: Post-pipeline analysis API"},{"location":"cookbooks/2-arabidopsis-gwas/","text":"Workflow diagram %%{init: {'theme': 'base', 'themeVariables': { 'primaryColor': 'grey', 'titleColor': '#262626', 'background': green}}}%% graph LR A(kcount) B(kfilter) C(kmatrix) D(kgwas) subgraph kmerkit modules A --> B --> C --> D end style A fill:teal,stroke:#333,stroke-width:2px,color:#262626 style B fill:goldenrod,stroke:#333,stroke-width:2px,color:#262626 Study description Explain and cite Arabidopsis studies here... ...","title":"GWAS WGS many traits (Arabidopsis)"},{"location":"cookbooks/2-arabidopsis-gwas/#workflow-diagram","text":"%%{init: {'theme': 'base', 'themeVariables': { 'primaryColor': 'grey', 'titleColor': '#262626', 'background': green}}}%% graph LR A(kcount) B(kfilter) C(kmatrix) D(kgwas) subgraph kmerkit modules A --> B --> C --> D end style A fill:teal,stroke:#333,stroke-width:2px,color:#262626 style B fill:goldenrod,stroke:#333,stroke-width:2px,color:#262626","title":"Workflow diagram"},{"location":"cookbooks/2-arabidopsis-gwas/#study-description","text":"Explain and cite Arabidopsis studies here...","title":"Study description"},{"location":"cookbooks/2-arabidopsis-gwas/#_1","text":"","title":"..."},{"location":"cookbooks/3-pedicularis-RAD-gwas/","text":"Workflow diagram %%{init: {'theme': 'dark', \"flowchart\" : { \"curve\" : \"basis\" } } }%% graph LR 0(kinit) 1(ktrim) A(kcount) B(kfilter) C(kmatrix) D(kgwas) 0 --> 1 --> A --> B --> C --> D linkStyle default stroke-width:2px,fill:none,stroke:grey; Study description Here we re-implement the study by Eaton et al. (in prep) to detect genomic loci associated with a novel floral trait in the plant species complex Pedicularis cranolopha . This study uses single-end RAD-seq data to sequence 100 individuals from 18 populations which vary in presence/absence of the trait of interest in a way that is discordant with the phylogeny. Citation in future Fetch fastq data If you wish to follow along you can dowload the data from SRA with the instructions below. Download fastq data using sra-tools Download the latest version of the sratools from https://github.com/ncbi/sra-tools/wiki/01.-Downloading-SRA-Toolkit by selecting the compiled binaries that are appropriate for your system (e.g., Linux or MacOSX). (I really do recommend that you use the latest version since this software is updated frequently and does not maintain compatibility with older versions.) Run the command below to download the fastq data for this study into a new directory. # make a directory to store the raw fastq data files mkdir -p ./fastq-data # download files to the specified fastq directory for run in ERR4161581 ERR4161582 ERR4161583 ERR4161584 ; do fasterq-dump --progress --outdir ./fastq-data --temp . $run ; done Kmerkit analysis Initialize a new project We start by initing a new project to assign samples names to files. The data are single-end kmerkit init --name forked --workdir /tmp --delim \"_\" ./fastq-data/*.gz This step creates a project JSON file, which will contain the fully reproducible information about each step in a kmerkit analysis. This file is updated upon each kmerkit module that is run. This file can be read directly, or, you can access a more nicely formatted view of specific results by calling kmerkit stats and specifying a specific module. kmerkit stats --json /tmp/forked.json init kmerkit stats output ... Read trimming (optional) We applied read-trimming using the default options in fastp , but also used the option --subsample 2e6 to normalize the number of reads among samples to a maximum of 2M. kmerkit trim --json /tmp/forked.json --workers 4 kmerkit stats --json /tmp/forked.json trim kmerkit stats output ... Count kmers Because RAD-seq generates data that extends directionally away from a cut-site the resulting reads will have specific orientations. Thus, we turn off canonical kmer counting here to count each kmer and its reverse-complement as separate patterns. kmerkit count --json /tmp/forked.json \\ --no-canonical --kmer-size 17 --min-depth 5 --workers 4 kmerkit stats --json /tmp/forked.json count kmerkit stats output ... Filter kmers Here I assign samples to either the target group (1) or the filter group (0) and keep kmers that occur in the frequency range 0.5-1.0 in the target, and exclude any that occur at all (i.e., in the range 0.0-1.0) in the filter group. kmerkit filter \\ --json /tmp/forked.json \\ -1 '...' \\ -0 '...' \\ --min_map 0 .0 0 .5 \\ --max_map 0 .0 1 .0 kmerkit stats -j /tmp/dioecy.json filter kmerkit filter results ... Perform GWAS Now that we've identified a set of target kmers we will extract reads from fastq data files that contain these kmers. This is expected to pull out reads mapping to male-specific regions of the A. palmeri genome. Here you can enter new fastq files to extract data from, or enter the names of samples already in the project database, which will use the (trimmed) fastq data files referenced in the JSON file. Here I don't enter any sample names, which defaults to performing extractions on all 4 samples in the database (we expect to not recover any reads for the two female pop samples). kmerkit gwas --json /tmp/forked.json --kinship --logistic kmerkit stats output ... Reproducibility In addition to your scripts that can be used to reproduce your analysis, the JSON project file contains a full record of the samples, parameters, and the order of analysis steps that make up your analysis. kmerkit project JSON file ... TODO: Post-pipeline analysis/visualization API The kmerkit Python API can be used to perform post-pipeline analyses in a jupyter notebook. Here we create a plot of import kmerkit project = kmerkit . load_json ( \"/tmp/forked.json\" ) ...","title":"GWAS RAD-seq"},{"location":"cookbooks/3-pedicularis-RAD-gwas/#workflow-diagram","text":"%%{init: {'theme': 'dark', \"flowchart\" : { \"curve\" : \"basis\" } } }%% graph LR 0(kinit) 1(ktrim) A(kcount) B(kfilter) C(kmatrix) D(kgwas) 0 --> 1 --> A --> B --> C --> D linkStyle default stroke-width:2px,fill:none,stroke:grey;","title":"Workflow diagram"},{"location":"cookbooks/3-pedicularis-RAD-gwas/#study-description","text":"Here we re-implement the study by Eaton et al. (in prep) to detect genomic loci associated with a novel floral trait in the plant species complex Pedicularis cranolopha . This study uses single-end RAD-seq data to sequence 100 individuals from 18 populations which vary in presence/absence of the trait of interest in a way that is discordant with the phylogeny. Citation in future","title":"Study description"},{"location":"cookbooks/3-pedicularis-RAD-gwas/#fetch-fastq-data","text":"If you wish to follow along you can dowload the data from SRA with the instructions below. Download fastq data using sra-tools Download the latest version of the sratools from https://github.com/ncbi/sra-tools/wiki/01.-Downloading-SRA-Toolkit by selecting the compiled binaries that are appropriate for your system (e.g., Linux or MacOSX). (I really do recommend that you use the latest version since this software is updated frequently and does not maintain compatibility with older versions.) Run the command below to download the fastq data for this study into a new directory. # make a directory to store the raw fastq data files mkdir -p ./fastq-data # download files to the specified fastq directory for run in ERR4161581 ERR4161582 ERR4161583 ERR4161584 ; do fasterq-dump --progress --outdir ./fastq-data --temp . $run ; done","title":"Fetch fastq data"},{"location":"cookbooks/3-pedicularis-RAD-gwas/#kmerkit-analysis","text":"","title":"Kmerkit analysis"},{"location":"cookbooks/3-pedicularis-RAD-gwas/#initialize-a-new-project","text":"We start by initing a new project to assign samples names to files. The data are single-end kmerkit init --name forked --workdir /tmp --delim \"_\" ./fastq-data/*.gz This step creates a project JSON file, which will contain the fully reproducible information about each step in a kmerkit analysis. This file is updated upon each kmerkit module that is run. This file can be read directly, or, you can access a more nicely formatted view of specific results by calling kmerkit stats and specifying a specific module. kmerkit stats --json /tmp/forked.json init kmerkit stats output ...","title":"Initialize a new project"},{"location":"cookbooks/3-pedicularis-RAD-gwas/#read-trimming-optional","text":"We applied read-trimming using the default options in fastp , but also used the option --subsample 2e6 to normalize the number of reads among samples to a maximum of 2M. kmerkit trim --json /tmp/forked.json --workers 4 kmerkit stats --json /tmp/forked.json trim kmerkit stats output ...","title":"Read trimming (optional)"},{"location":"cookbooks/3-pedicularis-RAD-gwas/#count-kmers","text":"Because RAD-seq generates data that extends directionally away from a cut-site the resulting reads will have specific orientations. Thus, we turn off canonical kmer counting here to count each kmer and its reverse-complement as separate patterns. kmerkit count --json /tmp/forked.json \\ --no-canonical --kmer-size 17 --min-depth 5 --workers 4 kmerkit stats --json /tmp/forked.json count kmerkit stats output ...","title":"Count kmers"},{"location":"cookbooks/3-pedicularis-RAD-gwas/#filter-kmers","text":"Here I assign samples to either the target group (1) or the filter group (0) and keep kmers that occur in the frequency range 0.5-1.0 in the target, and exclude any that occur at all (i.e., in the range 0.0-1.0) in the filter group. kmerkit filter \\ --json /tmp/forked.json \\ -1 '...' \\ -0 '...' \\ --min_map 0 .0 0 .5 \\ --max_map 0 .0 1 .0 kmerkit stats -j /tmp/dioecy.json filter kmerkit filter results ...","title":"Filter kmers"},{"location":"cookbooks/3-pedicularis-RAD-gwas/#perform-gwas","text":"Now that we've identified a set of target kmers we will extract reads from fastq data files that contain these kmers. This is expected to pull out reads mapping to male-specific regions of the A. palmeri genome. Here you can enter new fastq files to extract data from, or enter the names of samples already in the project database, which will use the (trimmed) fastq data files referenced in the JSON file. Here I don't enter any sample names, which defaults to performing extractions on all 4 samples in the database (we expect to not recover any reads for the two female pop samples). kmerkit gwas --json /tmp/forked.json --kinship --logistic kmerkit stats output ...","title":"Perform GWAS"},{"location":"cookbooks/3-pedicularis-RAD-gwas/#reproducibility","text":"In addition to your scripts that can be used to reproduce your analysis, the JSON project file contains a full record of the samples, parameters, and the order of analysis steps that make up your analysis. kmerkit project JSON file ...","title":"Reproducibility"},{"location":"cookbooks/3-pedicularis-RAD-gwas/#todo-post-pipeline-analysisvisualization-api","text":"The kmerkit Python API can be used to perform post-pipeline analyses in a jupyter notebook. Here we create a plot of import kmerkit project = kmerkit . load_json ( \"/tmp/forked.json\" ) ...","title":"TODO: Post-pipeline analysis/visualization API"}]}